{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39df492",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this project, we aim to develop a sophisticated garbage classification system leveraging the ResNet50 architecture. Our primary dataset serves as a foundation for building models that can eventually automate waste segregation, a critical step in optimizing recycling and waste management, ultimately aiding in environmental conservation. A notable challenge encountered is the inherent class imbalance within the dataset, prompting the exploration of data augmentation, and varied evaluation metrics. The project journey encompasses a comprehensive dataset analysis, addresses the imbalance, and delves deep into building and evaluating models both from scratch and through transfer learning with ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dec309",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- **Dataset Exploration:** Dive into the garbage dataset, emphasizing class imbalances.\n",
    "- **Tackle Imbalance:** Utilize class weights in the loss function to address dataset disparities.\n",
    "- **Implement Data Augmentation:** Enhance model generalization and combat overfitting.\n",
    "- **Construct ResNet50:** Design a custom ResNet50 for garbage classification from scratch.\n",
    "- **Employ Transfer Learning:** Leverage a pre-trained ResNet50, adapting it for our specific dataset.\n",
    "- **Evaluate Models:** Assess both models' performance using varied metrics to ensure reliable classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Activation, Add, Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2063259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard folder contains 403 images.\n",
      "glass folder contains 501 images.\n",
      "metal folder contains 410 images.\n",
      "paper folder contains 594 images.\n",
      "plastic folder contains 482 images.\n",
      "trash folder contains 137 images.\n",
      "\n",
      "All images in the dataset have the same dimensions: 512x384 with 3 color channels.\n"
     ]
    }
   ],
   "source": [
    "# Define the path where our dataset is stored\n",
    "dataset_path = './TrashType_Image_Dataset'\n",
    "\n",
    "# Retrieve the names of all folders (representing trash types) within the dataset directory\n",
    "garbage_types = os.listdir(dataset_path)\n",
    "\n",
    "# Set to store unique image dimensions for the entire dataset\n",
    "all_dimensions_set = set()\n",
    "\n",
    "# Iterate over each trash type (folder) to process images\n",
    "for garbage_type in garbage_types:\n",
    "    folder_path = os.path.join(dataset_path, garbage_type)\n",
    "    \n",
    "    # Verify that the current item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg'))]\n",
    "        \n",
    "        # Display the count of images in the current folder\n",
    "        num_images = len(image_files)\n",
    "        print(f\"{garbage_type} folder contains {num_images} images.\")\n",
    "        \n",
    "        # Loop over each image to check its dimensions\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            with Image.open(image_path) as img:\n",
    "                # Extract the width, height, and channels (color depth) of the image and add to the dimensions set\n",
    "                width, height = img.size\n",
    "                channels = len(img.getbands())\n",
    "                all_dimensions_set.add((width, height, channels))\n",
    "                \n",
    "# Determine if all images in the entore dataset have the same dimensions \n",
    "if len(all_dimensions_set) == 1: \n",
    "    width, height, channel = all_dimensions_set.pop()\n",
    "    print(f\"\\nAll images in the dataset have the same dimensions: {width}x{height} with {channels} color channels.\")\n",
    "else:\n",
    "    print(\"\\nThe images in the dataset have different dimensions or color channels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
